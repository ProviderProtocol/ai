/**
 * Provider-specific parameters for Google Gemini API requests.
 *
 * These parameters are passed through to the Google `generationConfig` field
 * and control model behavior such as output length, randomness, and sampling
 * strategies. All fields are optional and will use Google's defaults if omitted.
 *
 * @example
 * ```typescript
 * const params: GoogleLLMParams = {
 *   maxOutputTokens: 2048,
 *   temperature: 0.7,
 *   topP: 0.9,
 *   stopSequences: ['\n\n'],
 * };
 *
 * const response = await model.complete({
 *   messages: [...],
 *   config: { apiKey: '...' },
 *   params,
 * });
 * ```
 *
 * @see {@link https://ai.google.dev/api/rest/v1beta/GenerationConfig Google GenerationConfig docs}
 */
export interface GoogleLLMParams {
  /** Maximum number of tokens to generate */
  maxOutputTokens?: number;

  /** Temperature for randomness (0.0 - 2.0) */
  temperature?: number;

  /** Top-p (nucleus) sampling */
  topP?: number;

  /** Top-k sampling */
  topK?: number;

  /** Stop sequences */
  stopSequences?: string[];

  /** Number of candidates to generate */
  candidateCount?: number;

  /** Response MIME type */
  responseMimeType?: 'text/plain' | 'application/json';

  /** Response schema for structured output */
  responseSchema?: Record<string, unknown>;

  /**
   * Presence penalty for new topics
   * Positive values encourage discussing new topics
   */
  presencePenalty?: number;

  /**
   * Frequency penalty for repeated tokens
   * Positive values discourage repetition
   */
  frequencyPenalty?: number;

  /**
   * Seed for deterministic sampling
   * Same seed with same parameters should produce same results
   */
  seed?: number;

  /**
   * Whether to return log probabilities in response
   */
  responseLogprobs?: boolean;

  /**
   * Number of log probabilities to return (requires responseLogprobs: true)
   */
  logprobs?: number;

  /**
   * Whether to include audio timestamps in response
   */
  audioTimestamp?: boolean;

  /**
   * Thinking/reasoning configuration for Gemini 3+ models
   */
  thinkingConfig?: GoogleThinkingConfig;
}

/**
 * Configuration for extended thinking/reasoning in Gemini 3+ models.
 *
 * Enables models to spend additional compute on reasoning before
 * generating a response, improving quality for complex tasks.
 */
export interface GoogleThinkingConfig {
  /** Token budget allocated for model thinking/reasoning before response generation. */
  thinkingBudget?: number;
}

/**
 * Request body structure for Google Generative Language API.
 *
 * This interface represents the complete request payload sent to Google's
 * generateContent or streamGenerateContent endpoints.
 */
export interface GoogleRequest {
  /** Array of content turns representing the conversation history. */
  contents: GoogleContent[];
  /** Optional system instruction provided separately from conversation content. */
  systemInstruction?: {
    parts: GooglePart[];
  };
  /** Generation parameters controlling model output behavior. */
  generationConfig?: {
    maxOutputTokens?: number;
    temperature?: number;
    topP?: number;
    topK?: number;
    stopSequences?: string[];
    candidateCount?: number;
    responseMimeType?: string;
    responseSchema?: Record<string, unknown>;
    presencePenalty?: number;
    frequencyPenalty?: number;
    seed?: number;
    responseLogprobs?: boolean;
    logprobs?: number;
    audioTimestamp?: boolean;
    thinkingConfig?: GoogleThinkingConfig;
  };
  /** Function/tool declarations available for the model to call. */
  tools?: GoogleTool[];
  /** Safety filter settings to control content moderation. */
  safetySettings?: GoogleSafetySetting[];
}

/**
 * A single content turn in the Google conversation format.
 *
 * Represents either a user message or model response, containing
 * one or more parts that can be text, images, or function calls/responses.
 */
export interface GoogleContent {
  /** Role indicating message source: 'user' for user input, 'model' for assistant responses. */
  role: 'user' | 'model';
  /** Array of content parts within this message turn. */
  parts: GooglePart[];
}

/**
 * Union type for all possible content part types in Google messages.
 *
 * Parts can contain text, inline images, function calls (from model),
 * or function responses (from user providing tool results).
 */
export type GooglePart =
  | GoogleTextPart
  | GoogleImagePart
  | GoogleFunctionCallPart
  | GoogleFunctionResponsePart;

/**
 * Text content part.
 */
export interface GoogleTextPart {
  /** The text content. */
  text: string;
}

/**
 * Inline image content part with base64-encoded data.
 */
export interface GoogleImagePart {
  /** Inline image data container. */
  inlineData: {
    /** MIME type of the image (e.g., 'image/png', 'image/jpeg'). */
    mimeType: string;
    /** Base64-encoded image data. */
    data: string;
  };
}

/**
 * Function call part generated by the model.
 *
 * Represents the model's request to invoke a declared function with
 * specific arguments.
 */
export interface GoogleFunctionCallPart {
  /** Function call details. */
  functionCall: {
    /** Name of the function to call. */
    name: string;
    /** Arguments to pass to the function. */
    args: Record<string, unknown>;
  };
  /** Thought signature for Gemini 3+ models to maintain context across multi-turn tool calls. */
  thoughtSignature?: string;
}

/**
 * Function response part provided by the user.
 *
 * Contains the result of executing a function call, sent back to
 * the model to continue the conversation.
 */
export interface GoogleFunctionResponsePart {
  /** Function response details. */
  functionResponse: {
    /** Name of the function that was called. */
    name: string;
    /** Response data from the function execution. */
    response: Record<string, unknown>;
  };
}

/**
 * Tool definition containing function declarations.
 *
 * Google groups function declarations within a tools array, where each
 * tool object contains an array of function declarations.
 */
export interface GoogleTool {
  /** Array of function declarations available for the model to call. */
  functionDeclarations: GoogleFunctionDeclaration[];
}

/**
 * Declaration of a callable function/tool for the model.
 *
 * Describes the function signature including its name, purpose,
 * and expected parameters in JSON Schema format.
 */
export interface GoogleFunctionDeclaration {
  /** Unique name of the function. */
  name: string;
  /** Human-readable description of what the function does. */
  description: string;
  /** JSON Schema describing the function parameters. */
  parameters: {
    /** Schema type, always 'object' for function parameters. */
    type: 'object';
    /** Map of parameter names to their JSON Schema definitions. */
    properties: Record<string, unknown>;
    /** Array of required parameter names. */
    required?: string[];
  };
}

/**
 * Safety filter configuration for content moderation.
 *
 * Allows customization of safety thresholds for different harm categories.
 */
export interface GoogleSafetySetting {
  /** Harm category to configure (e.g., 'HARM_CATEGORY_HARASSMENT'). */
  category: string;
  /** Blocking threshold (e.g., 'BLOCK_NONE', 'BLOCK_LOW_AND_ABOVE'). */
  threshold: string;
}

/**
 * Response structure from Google's generateContent endpoint.
 *
 * Contains one or more candidate responses along with usage metadata.
 */
export interface GoogleResponse {
  /** Array of candidate responses (typically one unless candidateCount > 1). */
  candidates: GoogleCandidate[];
  /** Token usage statistics for billing and monitoring. */
  usageMetadata?: {
    /** Number of tokens in the input prompt. */
    promptTokenCount: number;
    /** Number of tokens in the generated candidates. */
    candidatesTokenCount: number;
    /** Total tokens (prompt + candidates). */
    totalTokenCount: number;
  };
}

/**
 * A single candidate response from the model.
 */
export interface GoogleCandidate {
  /** The generated content including role and parts. */
  content: {
    /** Always 'model' for generated responses. */
    role: 'model';
    /** Array of response parts (text and/or function calls). */
    parts: GoogleResponsePart[];
  };
  /** Reason the model stopped generating. */
  finishReason: 'STOP' | 'MAX_TOKENS' | 'SAFETY' | 'RECITATION' | 'OTHER' | 'TOOL_USE' | null;
  /** Index of this candidate in the candidates array. */
  index: number;
  /** Safety ratings for the generated content. */
  safetyRatings?: GoogleSafetyRating[];
}

/**
 * Part types that can appear in model responses.
 *
 * Responses may contain text or function calls, but not images
 * or function responses (those are input-only).
 */
export type GoogleResponsePart = GoogleTextPart | GoogleFunctionCallPart;

/**
 * Safety rating for a specific harm category.
 */
export interface GoogleSafetyRating {
  /** The harm category being rated. */
  category: string;
  /** Probability level of the harm (e.g., 'NEGLIGIBLE', 'LOW', 'MEDIUM', 'HIGH'). */
  probability: string;
}

/**
 * Streaming response chunk from Google's streamGenerateContent endpoint.
 *
 * Has the same structure as GoogleResponse but fields may be partial
 * or omitted depending on what data is available in the current chunk.
 */
export interface GoogleStreamChunk {
  /** Partial candidate data for this chunk. */
  candidates?: GoogleCandidate[];
  /** Cumulative token usage (updated with each chunk). */
  usageMetadata?: {
    /** Number of tokens in the input prompt. */
    promptTokenCount: number;
    /** Number of tokens generated so far. */
    candidatesTokenCount: number;
    /** Total tokens consumed so far. */
    totalTokenCount: number;
  };
}
